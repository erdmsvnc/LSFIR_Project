{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path, numberofImage):\n",
    "    array = np.zeros([numberofImage, 64*32])\n",
    "    i = 0\n",
    "    for img in os.listdir(path):\n",
    "        img_path = path + \"/\" + img\n",
    "        img = Image.open(img_path, mode = \"r\")\n",
    "        data = np.asarray(img, dtype = \"uint8\")\n",
    "        data = data.flatten()\n",
    "        array[i,:] = data\n",
    "        i += 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_Train_neg_Tensor:  torch.Size([42000, 2048])\n",
      "Size of y_Train_neg_Tensor:  torch.Size([42000])\n",
      "Size of x_Train_pos_Tensor:  torch.Size([10000, 2048])\n",
      "Size of y_Train_pos_Tensor:  torch.Size([10000])\n",
      "Size of X_train:  torch.Size([52000, 2048])\n",
      "Size of Y_train:  torch.Size([52000])\n",
      "Size of x_Train_neg_Tensor:  torch.Size([18056, 2048])\n",
      "Size of y_Train_neg_Tensor:  torch.Size([18056])\n",
      "Size of x_Train_neg_Tensor:  torch.Size([5944, 2048])\n",
      "Size of y_Train_neg_Tensor:  torch.Size([5944])\n",
      "Size of X_train:  torch.Size([24000, 2048])\n",
      "Size of Y_train:  torch.Size([24000])\n"
     ]
    }
   ],
   "source": [
    "res_Train_neg_path = r\"/Users/erdemsevinc/Desktop/python/WEEK 11/LSIFIR/Classification/Train/neg\"\n",
    "res_num_Train_neg_img = 43390\n",
    "res_Train_neg_array = read_images(res_Train_neg_path, res_num_Train_neg_img)\n",
    "\n",
    "x_res_Train_neg_Tensor = torch.from_numpy(res_Train_neg_array[:42000,:])\n",
    "print(\"Size of x_Train_neg_Tensor: \", x_res_Train_neg_Tensor.size())\n",
    "\n",
    "# I specify negative images as zero.\n",
    "y_res_Train_neg_Tensor = torch.zeros(42000, dtype = torch.long)\n",
    "print(\"Size of y_Train_neg_Tensor: \", y_res_Train_neg_Tensor.size())\n",
    "\n",
    "res_Train_pos_path = r\"/Users/erdemsevinc/Desktop/python/WEEK 11/LSIFIR/Classification/Train/pos\"\n",
    "res_num_Train_pos_img = 10208\n",
    "res_Train_pos_array = read_images(res_Train_pos_path, res_num_Train_pos_img)\n",
    "\n",
    "x_res_Train_pos_Tensor = torch.from_numpy(res_Train_pos_array[:10000,:])\n",
    "print(\"Size of x_Train_pos_Tensor: \", x_res_Train_pos_Tensor.size())\n",
    "\n",
    "# I specify negative images as one.\n",
    "y_res_Train_pos_Tensor = torch.ones(10000, dtype = torch.long)\n",
    "print(\"Size of y_Train_pos_Tensor: \", y_res_Train_pos_Tensor.size())\n",
    "\n",
    "X_res_train = torch.cat((x_res_Train_neg_Tensor, x_res_Train_pos_Tensor),0)\n",
    "Y_res_train = torch.cat((y_res_Train_neg_Tensor, y_res_Train_pos_Tensor),0)\n",
    "\n",
    "print(\"Size of X_train: \",X_res_train.size())\n",
    "print(\"Size of Y_train: \",Y_res_train.size()) \n",
    "\n",
    "res_Test_neg_path = r\"/Users/erdemsevinc/Desktop/python/WEEK 11/LSIFIR/Classification/Test/neg\"\n",
    "res_num_Test_neg_img = 22050\n",
    "res_Test_neg_array = read_images(res_Test_neg_path, res_num_Test_neg_img)\n",
    "\n",
    "x_res_Test_neg_Tensor = torch.from_numpy(res_Test_neg_array[:18056,:])\n",
    "print(\"Size of x_Train_neg_Tensor: \", x_res_Test_neg_Tensor.size())\n",
    "\n",
    "# I specify negative images as zero.\n",
    "y_res_Test_neg_Tensor = torch.zeros(18056, dtype = torch.long)\n",
    "print(\"Size of y_Train_neg_Tensor: \", y_res_Test_neg_Tensor.size())\n",
    "\n",
    "res_Test_pos_path = r\"/Users/erdemsevinc/Desktop/python/WEEK 11/LSIFIR/Classification/Test/pos\"\n",
    "res_num_Test_pos_img = 5944\n",
    "res_Test_pos_array = read_images(res_Test_pos_path, res_num_Test_pos_img)\n",
    "\n",
    "x_res_Test_pos_Tensor = torch.from_numpy(res_Test_pos_array)\n",
    "print(\"Size of x_Train_neg_Tensor: \", x_res_Test_pos_Tensor.size())\n",
    "\n",
    "# I specify negative images as one.\n",
    "y_res_Test_pos_Tensor = torch.ones(res_num_Test_pos_img, dtype = torch.long)\n",
    "print(\"Size of y_Train_neg_Tensor: \", y_res_Test_pos_Tensor.size())\n",
    "\n",
    "X_res_test = torch.cat((x_res_Test_neg_Tensor, x_res_Test_pos_Tensor),0)\n",
    "Y_res_test = torch.cat((y_res_Test_neg_Tensor, y_res_Test_pos_Tensor),0)\n",
    "\n",
    "print(\"Size of X_train: \",X_res_test.size())\n",
    "print(\"Size of Y_train: \",Y_res_test.size()) \n",
    "\n",
    "res_batch_size = 2000\n",
    "\n",
    "# Last prepare data\n",
    "res_train = torch.utils.data.TensorDataset(X_res_train, Y_res_train)\n",
    "res_trainloader = torch.utils.data.DataLoader(res_train, batch_size = res_batch_size, shuffle = True)\n",
    "\n",
    "res_test = torch.utils.data.TensorDataset(X_res_test, Y_res_test)\n",
    "res_testloader = torch.utils.data.DataLoader(res_test, batch_size = res_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_res_train[45001,:].reshape(64,32),cmap = \"gray\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_numberofepochs = 10\n",
    "res_numberofclasses = 2\n",
    "res_learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 1, stride = stride, bias = False)\n",
    "\n",
    "class ResNetBasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride = 1, downsample = None):\n",
    "        super(ResNetBasicBlock,self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.drop = nn.Dropout(0.9)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.drop(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes = res_numberofclasses):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256*block.expansion, res_numberofclasses)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride = 1):\n",
    "        downsample = None\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                                      nn.BatchNorm2d(planes*block.expansion))\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes*block.expansion\n",
    "        for _ in range(1,blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "res_model = ResNet(ResNetBasicBlock, [2,2,2])\n",
    "\n",
    "# For GPU\n",
    "# res_model = ResNet(ResNetBasicBlock, [2,2,2]).to(device)\n",
    "\n",
    "res_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "res_optimizer = torch.optim.Adam(res_model.parameters(), lr = res_learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "res_optimizer = torch.optim.Adam(res_model.parameters(), lr = res_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Accuracy Train: 79.38076923076923 | Accuracy Test: 74.20416666666667 | Loss: 0.5235095024108887 \n",
      "Epoch: 1 | Accuracy Train: 79.74423076923077 | Accuracy Test: 73.6125 | Loss: 0.45060956478118896 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# backward and optimization\u001b[39;00m\n\u001b[1;32m     26\u001b[0m res_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     28\u001b[0m res_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mif i % 2 == 0:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    print(\"epoch: {} {}\\{}\".format(epoch, i, res_total_step))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_start = time.time() # start of time\n",
    "res_train_acc = []\n",
    "res_test_acc = []\n",
    "res_loss_list = []\n",
    "\n",
    "use_gpu = False # If you want to use GPU, Change True\n",
    "\n",
    "res_total_step = len(res_trainloader)\n",
    "\n",
    "for epoch in range(res_numberofepochs):\n",
    "    for i, (images, labels) in enumerate(res_trainloader):\n",
    "        \n",
    "        images = images.view(res_batch_size, 1, 64, 32)\n",
    "        images = images.float()\n",
    "        \n",
    "        # GPU\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "        outputs = res_model(images)\n",
    "        \n",
    "        loss = res_criterion(outputs, labels)\n",
    "        \n",
    "        # backward and optimization\n",
    "        res_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        res_optimizer.step()\n",
    "        \"\"\"\n",
    "        if i % 2 == 0:\n",
    "            print(\"epoch: {} {}\\{}\".format(epoch, i, res_total_step))\n",
    "        \"\"\" \n",
    "    # train\n",
    "    res_train_correct = 0\n",
    "    res_train_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in res_trainloader:\n",
    "            images, labels = data\n",
    "            images = images.view(res_batch_size, 1, 64, 32)\n",
    "            images = images.float()\n",
    "            \n",
    "            # GPU\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "            outputs = res_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            res_train_total += labels.size(0)\n",
    "            res_train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    Accuracy_Train = 100* res_train_correct/res_train_total\n",
    "    #print(\"Accuracy Train: \"(Accuracy_Train)\n",
    "    res_train_acc.append(Accuracy_Train)\n",
    "    \n",
    "    # test\n",
    "    res_test_correct = 0\n",
    "    res_test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in res_testloader:\n",
    "            images, labels = data\n",
    "            images = images.view(res_batch_size, 1, 64, 32)\n",
    "            images = images.float()\n",
    "            \n",
    "            # GPU\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "            outputs = res_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            res_test_total += labels.size(0)\n",
    "            res_test_correct += (predicted == labels).sum().item()\n",
    "          \n",
    "    Accuracy_Test = 100* res_test_correct/res_test_total\n",
    "    #print(\"Accuracy Test: \"(Accuracy_Test)\n",
    "    res_test_acc.append(Accuracy_Test)\n",
    "    \n",
    "    res_loss_list.append(loss.item())\n",
    "          \n",
    "    print(\"Epoch: {} | Accuracy Train: {} | Accuracy Test: {} | Loss: {} \".format(epoch, Accuracy_Train, Accuracy_Test, loss.item()))\n",
    "    \n",
    "print(\"Training is Done\")\n",
    "\n",
    "# time of end\n",
    "res_end = time.time()\n",
    "res_process_time = (res_end - res_start)/60\n",
    "print(\"Process Time: \",res_process_time)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(res_numberofepochs):\n\u001b[1;32m      3\u001b[0m     res_epochs\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(res_epochs, res_train_acc, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(res_epochs, res_test_acc, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain-Test Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_epochs = []\n",
    "for i in range(res_numberofepochs):\n",
    "    res_epochs.append(i)\n",
    "\n",
    "plt.plot(res_epochs, res_train_acc, label=\"Train\")\n",
    "plt.plot(res_epochs, res_test_acc, label=\"Test\")\n",
    "plt.title(\"Train-Test Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_loss_list)\n",
    "plt.title(\"Loss of ResNet Model\")\n",
    "plt.xlabel(\"Index of loss_list\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
